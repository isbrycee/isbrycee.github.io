<!DOCTYPE HTML>

<style>
  #full {
    display: none;
    font-size: 100px;
  }
</style>

<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Jing HAO</title>
	
  <meta name="author" content="Jing Hao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/me.png">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
</head>


<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
	      
	<!-- self-intro -->
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:73%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jing HAO</name>
              </p>
              <p>
	      I'm pursuing my Ph.D. degree in the University of HongKong, Faculty of Dentistry (Ranking 3rd in the world), specializing in  <font color="#FF0000"><strong>Clinical Artificial Intelligence</strong></font>, supervised by <a href="https://scholar.google.com/citations?user=17V5x14AAAAJ&hl=zh-CN">Prof. Kuo Feng Hung</a> and <a href="https://scholar.google.com/citations?user=mXzEprAAAAAJ">Prof. Tsoi, James Kit Hon</a>. 
              </p>
	      <p>
	      Previously, I worked as a Computer Vision Engineer on Baidu VIS from 2022.07 to 2024.08. I received my M.S. degree in Huazhong University of Science and Technology (HUST, 2022), and B.S. degree in Chinese University of Mining and Technology (CUMT, 2020).
	      </p>
              <p>
              My research interests span the area of computer vision, self-supervised pre-training, multimodal large language model (mllm), and AI4Science.
              </p>
              <p style="text-align:center;font-size:20px;">		      
                <a href="mailto:isjinghao@gmail.com" target="_blank"><button style='font-size:16px'><i class='fas fa-envelope'></i> e-mail</button> </a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=E8R8c00AAAAJ&hl=zh-CN" target="_blank"><button style='font-size:16px'><i class="ai ai-google-scholar"></i> Scholar</button></a> &nbsp/&nbsp
		<a href="https://github.com/isbrycee/" target="_blank"><button style='font-size:16px'><i class="fab fa-github"></i> github</button> </a> &nbsp/&nbsp
		<a href="https://mp.weixin.qq.com/s/Nc15If10h9tED3hL92JW3A" target="_blank"><button style='font-size:16px'><i class="fab fa-weixin icon"></i> Wechat</button> </a> &nbsp/&nbsp
		<a href="https://orcid.org/0000-0002-2305-1201" target="_blank"><button style='font-size:16px'><i class="fa fa-user icon"></i> ORCiD</button> </a> 

		<!-- <a href="" target="_blank"><button style='font-size:16px'><i class="fab fa-linkedin"></i> linkedin</button> </a>  -->
	      </p>
            </td>
            <td style="padding:3%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/me_2024.jpg" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    </tr>
  </tbody></table>
<!-- end self-intro -->
	
<!-- News -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <li style="margin: 5px;" > 
		[Oct.2024] I got 6th place in ToothFairy2 : Semi-supervised Teeth Segmentation hold on <b>MICCAI2024</b> !
              </li>  
	      <li style="margin: 5px;" > 
		[Sep.2024] One paper <a href="https://arxiv.org/pdf/2409.13540">FullAnno</a> has been released in Arxiv !
              </li>   
	      <li style="margin: 5px;" > 
		[July.2024] I got the firm offer from HKU, and had been a formal Ph.D. student !
              </li>
	      <li style="margin: 5px;" > 
		[July.2024] One paper <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024004301">METR</a> has been accepted to <b>Neural Networks</b> !
              </li>
	      <li style="margin: 5px;" >
                [Aug.2023] I have received my IELTS scores 7(6)!
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p><heading>Publications</heading></p>
              <p>
                See full list at <a href="https://scholar.google.com/citations?user=E8R8c00AAAAJ&hl=zh-CN">Google Scholar.</a> (* indicates equal contribution, # indicates corresponding author)
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	  <!-- FullAnno -->
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/framework_fullanno_v1.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://arxiv.org/pdf/2409.13540">
              <papertitle>FullAnno: A Data Engine for Enhancing Image Comprehension of MLLMs</papertitle>
              </a>
              <br>
              <font color="#FF0000"><strong>Jing Hao</strong></font>,
	      Yuxiang Zhao, 
	      Song Chen, 
	      Yanpeng Sun, 
	      Qiang Chen, 
	      <b>Jingdong Wang</b>
	      <br>
		<a href="https://arxiv.org/pdf/2409.13540">[paper]</a>
              <br>
              <em><b>Arxiv. preprint</b></em>
              <br>
              <p>We designed a FullAnno system, which is a data engine that can generate large-scale, high-quality, and fine-grained image caption datasets automatically.</p>
            </td>
          </tr>
	  <!-- SemiTNet -->
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/framework_SemiTNet.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://www.mdpi.com/2075-4418/14/17/1948">
              <papertitle>A semi-supervised transformer-based deep learning framework for automated tooth segmentation and identification on panoramic radiographs</papertitle>
              </a>
              <br>
              <font color="#FF0000"><strong>Jing Hao</strong></font>,
	      Lun M Wong, 
	      Zhiyi Shan, 
	      Qi Yong H. Ai, 
	      Xieqi Shi, 
	      James Kit Hon Tsoi,
	      Kuo Feng Hung #
	      <br>
		<a href="https://github.com/isbrycee/SemiTNet">[code]</a> | 
		<a href="https://github.com/isbrycee/SemiTNet"> <img alt="Github stars" src="https://img.shields.io/github/stars/isbrycee/SemiTNet?style=social"></a>
              <br>
              <em><b>Diagnostics, 2024 (JCR Q1, IF=3.0)</b></em>
              <br>
              <p>This study proposed a novel semi-supervised transformer-based framework designed for automated tooth segmentation and identification on panoramic radiographs.</p>
            </td>
          </tr>
		
	  <!-- T-Mamba -->
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/framework_T-Mamba.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://arxiv.org/pdf/2404.01065">
              <papertitle>T-Mamba: A unified framework with Long-Range Dependency in dual-domain for 2D & 3D Tooth Segmentation</papertitle>
              </a>
              <br>
              <font color="#FF0000"><strong>Jing Hao</strong></font>,
	      Yonghui Zhu,
	      Lei He,
              Moyun Liu,
	      Kuo Feng Hung
	      <br>
        	<a href="https://arxiv.org/pdf/2404.01065">[paper]</a>
		<a href="https://github.com/isbrycee/T-Mamba">[code]</a> | 
		<a href="https://github.com/isbrycee/T-Mamba"> <img alt="Github stars" src="https://img.shields.io/github/stars/isbrycee/T-Mamba?style=social"></a>
              <br>
              <em><b>Submitted to IEEE TMI</b></em>
              <br>
              <p>T-Mamba is the first work to introduce frequency-based features into vision mamba, its flexibility allows it to process both 2D and 3D tooth data without the need for separate modules.</p>
            </td>
          </tr>
		
	  <!-- GEM -->
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/framework_GEM.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://arxiv.org/pdf/2307.12018">
              <papertitle>GEM: Boost Simple Network for Glass Surface Segmentation via Vision Foundation Models</papertitle>
              </a>
              <br>
              <font color="#FF0000"><strong>Jing Hao</strong></font>,
              Moyun Liu,
	      Jinrong Yang,
	      Kuo Feng Hung
	      <br>
        	<a href="https://arxiv.org/pdf/2307.12018">[paper]</a>
		<a href="https://huggingface.co/datasets/Bryceee/S-GSD">[dataset]</a>
		<a href="https://github.com/isbrycee/GEM">[code]</a> | 
		<a href="https://github.com/isbrycee/GEM"> <img alt="Github stars" src="https://img.shields.io/github/stars/isbrycee/GEM?style=social"></a>
              <br>
              <em><b>Submitted to IEEE TMM</b></em>
              <br>
              <p>The first to propose exploring to the solution of glass surface segmentation by fully harnessing the capabilities of existing VFMs.</p>
            </td>
          </tr>
		
          <!-- METR -->
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/framework_METR.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024004301">
              <papertitle>Language-aware Multiple Datasets Detection Pretraining for DETRs</papertitle>
              </a>
              <br>
              <font color="#FF0000"><strong>Jing Hao</strong></font>,
              Song Chen
	      <br>
        	<a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024004301">[paper]</a>
		<a href="https://github.com/isbrycee/METR">[code]</a> | 
		<a href="https://github.com/isbrycee/METR"> <img alt="Github stars" src="https://img.shields.io/github/stars/isbrycee/METR?style=social"></a>
              <br>
              <em><b>Neural Networks, 2024 (JCR Q1, IF=7.9)</b></em>
              <br>
              <p>A strong framework for utilizing Multiple datasets to pretrain DETR-like detectors without the need for manual label spaces integration.</p>
            </td>
          </tr>
		
	  <!-- GSCA -->
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/framework_GSCA.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://openreview.net/pdf?id=isodM5jTA7h">
              <papertitle>Simple Parameter-free Self-attention Approximation</papertitle>
              </a>
              <br>
              YuwenZhai*,
              <font color="#FF0000"><strong>Jing Hao*</strong></font>,
              Liang Gao,
              Xinyu Li,
              Yiping Gao,
              Shumin Han
              <br>
	      <a href="https://openreview.net/pdf?id=isodM5jTA7h">[paper]</a>
	      <br>
              <em><b>ICLR Tiny Paper, 2023</b></em>
              <br>      
              <p>A self-attention approximation without training parameters which captures global spatial features with linear complexity.</p>
            </td>
          </tr>

	  <!-- ANAFNet -->
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/framework_ANAFNet.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://ieeexplore.ieee.org/abstract/document/10265123/">
              <papertitle>A Stronger Stitching Algorithm for Fisheye Images based on Deblurring and Registration</papertitle>
              </a>
              <br>
              <font color="#FF0000"><strong>Jing Hao</strong></font>,
              Jingming Xie, 
              Jinyuan Zhang, 
              Moyun Liu
              <br>
	      <a href="https://ieeexplore.ieee.org/abstract/document/10265123/">[paper]</a>
	      <br>
              <em><b>IEEE Sensors Letters, 2023</b></em>
              <!-- <br>
              <font color="#FF0000">The Strongest Detector under 1B Parameters. Rank Top-2 on COCO Leaderboard (2023.04)</font>
              </div> -->
              <p>A stronger stitching algorithm for fisheye images by combining the traditional image processing method with deep learning.</p>
            </td>
          </tr>

	<!-- GRNet -->
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/framework_X_ray.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://arxiv.org/pdf/2110.09278.pdf">
              <papertitle>A Lightweight and Accurate Recognition Framework for Signs of X-ray Weld Images</papertitle>
              </a>
              <br>
              Moyun Liu,
              Jingming Xie,
              <font color="#FF0000"><strong>Jing Hao</strong></font>,
              Yang Zhang, 
              Xuzhan Chen, 
              Youping Chen
              <br>
	      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0166361521001664">[paper]</a>
	      <br>
              <em><b>Computers in Industry, 2022, (JCR Q1, IF=8.2)</b></em>
              <br>
              <p>A signs recognition framework based on convolutional neural networks (CNNs) for weld images.</p>
            </td>
          </tr>
        </tbody></table>
	
<!-- Competitions -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Competition</heading>
            <p>
	      <li style="margin: 5px;" > 
		The 6th place in ToothFairy2 : Semi-supervised Teeth Segmentation hold on <b>MICCAI2024</b>
              </li>	  
	      <img style="width:20%;max-width:20%" src="images/certificate_6th_MICCAI2024.png" align="center">
            </p>
          </td>
        </tr>
      </tbody></table>
<!-- End Competition -->
	
<!-- Services -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Services</heading>
            <p>
	      <li style="margin: 5px;" > 
		Reviewer for <b>IEEE Transactions on Circuits and Systems for Video Technology</b>
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
<!-- End Services -->
	
<!-- Education & Experience -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p><heading>Education & Experience</heading></p>

	<!-- HKU -->
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/hku_logo.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://www.hku.hk/">
              <papertitle>The University of Hong Kong (HKU)</papertitle>
              </a>
              <br> <em>2024.09 - now</em>
	      <br> <strong>Ph.D Student</strong>, <a href="https://facdent.hku.hk/"><d>Faculty of Dentistry (Ranking 3rd in the world)</d></a>
	      <br> <font color="#FF0000"><strong> Clinical Artificial Intelligence </strong></font>
            </td>
          </tr>
		
	<!-- Baidu -->
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/baidu_logo.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="">
              <papertitle>Baidu VIS</papertitle>
              </a>
              <br> <em>2022.07 - 2024.08</em>
	      <br> <strong>Computer Vision Engineer</strong>
            </td>
          </tr>
		
	<!-- HUST -->
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/hust_logo.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="http://english.hust.edu.cn/">
              <papertitle>Huazhong University of Science and Technology (HUST)</papertitle>
              </a>
              <br> <em>2020.09 - 2022.06</em>
	      <br> <strong>Master Student</strong>, <a href="http://mse.hust.edu.cn/"><d>School of Mechanical Science and Engineering</d></a> 
            </td>
          </tr>
		
	<!-- CUMT -->
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/cumt_logo.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <a href="https://global.cumt.edu.cn/">
              <papertitle>China University of Mining and Technology (CUMT)</papertitle>
              </a>
              <br> <em>2016.09 - 2020.06</em>
	      <br> <strong>Undergraduate Student</strong>, <a href="https://cmee.cumt.edu.cn/"><d>School of Mechanical and Electrical Engineering</d></a> 
            </td>
          </tr>
          </td>
          </tr>
      </tbody></table>
<!-- End Education & Experience -->
	
<!-- Selected Awards and Honors -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <p><heading>Selected Awards & Honors</heading></p>
            <p>
                <li style="margin: 5px;" >
                  <b><font color="#FF0000">National Scholarship</font></b> (2018)
                </li>
                <li style="margin: 5px;" >
                  First-class Scholarship in HUST (2021)
                </li>
                <li style="margin: 5px;" >
                  First-class Scholarship in CUMT (2019)
                </li>
                <li style="margin: 5px;" >
                  Second-class Scholarship in CUMT (2017)
                </li>
                <li style="margin: 5px;" >
                  Outstanding student in CUMT (2018)
                </li>
                <li style="margin: 5px;" >
                  Excellent Student Leader in Jiangsu Province (2019)
                </li>
                <li style="margin: 5px;" >
                  Excellent Young Volunteer in Xuzhou City (2019)
                </li>
              </p>
            <!-- <p>
               * indicates project lead, # indicates directional lead
            </p> -->
          </td>
        </tr>
      </tbody></table>
<!-- End Selected Awards and Honors -->
	
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- <div id="click">
            <p align=right><a href="#Show-the-full-publication-list" style="padding:20px;" onclick="showStuff(this);">Full publication list</a></p>
           </div>
           <script>
             function showStuff(txt) {
               document.getElementById("full").style.display = "block";
               document.getElementById("click").style.display = "none";
              //  document.getElementById("selected").style.display = "none";
             }
             </script> -->
 
<!-- <p><center>
	  <div id="clustrmaps-widget" style="width:5%">
	  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=yp3s8rdiQW_pbzmBOzWDx2Fv6afIlEpV-k1EZiYIkEY"></script>
	  </div>        
	  <br>
	    &copy; Tianhe Ren | Last updated: Nov 9, 2022
</center></p>
</body> -->

</html>
